The idea behind a mapping model is to take measurements from isolated task executions and adjust them to predict the behavior when tasks run concurrently. Hereâ€™s a step-by-step guide to designing and implementing such a mapping model:

1. Data Collection
a. Isolated Measurements:

Run each task independently (i.e., one task at a time) on each device (Nano and Xavier).
Record metrics for each task, such as:
Energy Consumption: Measured via tegrastats.
CPU Load, Memory Usage, and Temperature: Collected via Docker stats.
Execution Time: Start/stop timestamps from your code.
Store these metrics with a unique task ID and record the task parameters (e.g., cycles, potential values).
b. Concurrent Measurements:

Run controlled experiments where multiple tasks execute concurrently on the same device.
Record the same metrics as above for each task (or the aggregate if individual tasks arenâ€™t separately measurable).
Label the experiments with the number of concurrent tasks and other relevant parameters.
2. Data Preprocessing
a. Synchronize and Align Data:

Use timestamps or unique IDs to align isolated and concurrent measurements.
Normalize the values if necessary (e.g., scale energy consumption to a common range).
b. Feature Engineering:

Input Features: Use the isolated metrics (e.g., energy per task, CPU load, execution time).
Additional Features: Include the number of concurrent tasks and possibly interaction terms (e.g., isolated energy * number of tasks).
Output Variable: The measured metric under concurrent execution (e.g., total energy consumption, average CPU load).
3. Model Development
a. Choose a Modeling Approach:

Linear Regression: A simple starting point where you model the concurrent metric as a linear combination of the isolated metrics and the concurrency level.
For example:
ğ¸
ğ‘
ğ‘œ
ğ‘›
ğ‘
ğ‘¢
ğ‘Ÿ
ğ‘Ÿ
ğ‘’
ğ‘›
ğ‘¡
=
ğ›½
0
+
ğ›½
1
â‹…
ğ¸
ğ‘–
ğ‘ 
ğ‘œ
ğ‘™
ğ‘
ğ‘¡
ğ‘’
ğ‘‘
+
ğ›½
2
â‹…
ğ‘
+
ğœ–
E 
concurrent
â€‹
 =Î² 
0
â€‹
 +Î² 
1
â€‹
 â‹…E 
isolated
â€‹
 +Î² 
2
â€‹
 â‹…N+Ïµ
Here, 
ğ¸
ğ‘
ğ‘œ
ğ‘›
ğ‘
ğ‘¢
ğ‘Ÿ
ğ‘Ÿ
ğ‘’
ğ‘›
ğ‘¡
E 
concurrent
â€‹
  is the observed energy under concurrency, 
ğ¸
ğ‘–
ğ‘ 
ğ‘œ
ğ‘™
ğ‘
ğ‘¡
ğ‘’
ğ‘‘
E 
isolated
â€‹
  is the baseline energy from an isolated run, 
ğ‘
N is the number of tasks running concurrently, and 
ğ›½
Î²â€™s are the coefficients.
Non-linear Models: If the relationship is not linear, consider polynomial regression, decision trees, or even a neural network model.
Hybrid Models: You might also include interaction terms or use ensemble methods if you suspect that the interference effects are complex.
b. Training the Model:

Split your dataset into training and testing sets.
Use a tool like Pythonâ€™s scikit-learn for regression analysis:
Fit the model on the training set.
Evaluate using metrics like RÂ², MAE (Mean Absolute Error), or RMSE (Root Mean Square Error).
c. Model Validation:

Cross-validation: Ensure that your model generalizes well by using k-fold cross-validation.
Residual Analysis: Check the residuals (differences between predicted and observed values) to validate model assumptions.
Sensitivity Analysis: Evaluate how changes in the number of concurrent tasks affect the prediction.
4. Model Integration
a. Correction Factors:

Once your model is trained, the coefficients (or model parameters) become your â€œscaling factors.â€
For instance, if your model shows that energy consumption scales non-linearly with the number of concurrent tasks, use the model to predict the adjusted energy consumption for any given isolated measurement.
b. Use in Offloading Decisions:

Integrate the mapping model into your offloading decision engine.
When a new task is about to be offloaded, estimate its isolated metrics and then use your mapping function to predict its performance in a concurrent setting.
Use these predictions as part of your reward function or scheduling criteria to choose the optimal offloading strategy.
